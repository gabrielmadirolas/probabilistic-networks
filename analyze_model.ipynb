{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af4a4735-c4fb-4d76-8e31-64202fca715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba227e99-28a8-49b7-94be-fa47ceca3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models_path = './checkpoints/saved_model_epoch'\n",
    "models_list = glob.glob(saved_models_path+'*')\n",
    "models_list.sort(key=os.path.getmtime)\n",
    "#print(models_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2dddedd-275c-4430-a7d9-893a89dbb6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000])\n",
      "odict_keys(['_orig_mod.lstm.layers.0.cell.weight_ih', '_orig_mod.lstm.layers.0.cell.weight_hh', '_orig_mod.lstm.layers.0.cell.bias_ih', '_orig_mod.lstm.layers.0.cell.bias_hh', '_orig_mod.lstm.layers.0.cell.sigma.sigma', '_orig_mod.linear.weight', '_orig_mod.linear.bias'])\n",
      "mean sigma: 0.2488\n",
      "std sigma: 0.0487\n",
      "--------------------------\n",
      "mean sigma: 0.2473\n",
      "std sigma: 0.0508\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(models_list[0])\n",
    "print(model['_orig_mod.lstm.layers.0.cell.sigma.sigma'].shape)\n",
    "print(model.keys())\n",
    "for model in models_list:\n",
    "    model = torch.load(model)\n",
    "    if '_orig_mod.lstm.layers.0.cell.sigma.mu' in model:\n",
    "        print('mean mu:',f'{model['_orig_mod.lstm.layers.0.cell.sigma.mu'].mean().item():.4f}')\n",
    "        print('std mu:',f'{model['_orig_mod.lstm.layers.0.cell.sigma.mu'].std().item():.4f}')\n",
    "    print('mean sigma:',f'{model['_orig_mod.lstm.layers.0.cell.sigma.sigma'].mean().item():.4f}')\n",
    "    print('std sigma:',f'{model['_orig_mod.lstm.layers.0.cell.sigma.sigma'].std().item():.4f}')\n",
    "    print('--------------------------')\n",
    "    #print(model['_orig_mod.lstm.layers.0.cell.sigma.sigma'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f242df69-131e-4776-8304-a299a6dbed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 500])\n",
      "tensor([-2.0841,  1.9260,  0.3573, -1.1646, -1.5593])\n",
      "torch.Size([2000, 500])\n",
      "tensor([-2.0841,  1.9260,  0.3459, -1.1646, -1.5593])\n"
     ]
    }
   ],
   "source": [
    "for model in models_list:\n",
    "    model = torch.load(model)\n",
    "    print(model['_orig_mod.lstm.layers.0.cell.weight_hh'].shape)\n",
    "    print(model['_orig_mod.lstm.layers.0.cell.bias_hh'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2382eac9-38d7-426a-b09a-5745b5474a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1])\n",
      "tensor([-0.4198, -0.9840, -1.0608, -0.7250, -0.8990])\n",
      "torch.Size([2000, 1])\n",
      "tensor([-0.4198, -0.9840, -1.0721, -0.7250, -0.8990])\n"
     ]
    }
   ],
   "source": [
    "for model in models_list:\n",
    "    model = torch.load(model)\n",
    "    print(model['_orig_mod.lstm.layers.0.cell.weight_ih'].shape)\n",
    "    print(model['_orig_mod.lstm.layers.0.cell.bias_ih'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6e5d43-7804-47ee-870a-681912a12749",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for model in models_list:\n",
    "    model = torch.load(model)\n",
    "    print(model['_orig_mod.linear.weight'])\n",
    "    print(model['_orig_mod.linear.bias'])\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42521ced-d8df-4dd5-b40e-048e93ff06ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2}\n",
      "{'a': 1, 'b': 2}\n",
      "ponó\n"
     ]
    }
   ],
   "source": [
    "dict1 = {'a': 1, 'b': 2}\n",
    "dict2 = {'a': 3, 'b': 4}\n",
    "dict3 = {'dict1':dict1, 'dict2':dict2}\n",
    "dict4 = dict3.get('dict1',{})\n",
    "print(dict4)\n",
    "dict5 = dict3['dict1']\n",
    "print(dict5)\n",
    "if 'f' in dict5:\n",
    "    print('pozí')\n",
    "else:\n",
    "    print('ponó')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
